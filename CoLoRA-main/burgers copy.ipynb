{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import vmap\n",
    "import jax.numpy as jnp\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "import jax\n",
    "import matplotlib.pyplot as plt\n",
    "from jax.experimental.ode import odeint\n",
    "from colora.data import load_all_hdf5, split_data_by_mu, prepare_coordinate_data\n",
    "data_dir = Path('./data')\n",
    "data_path = data_dir / 'burgers'\n",
    "mus, sols, spacing = load_all_hdf5(data_path)\n",
    "\n",
    "train_mus = np.asarray([0.001, 0.00199, 0.00298, 0.00496, 0.00595, 0.00694, 0.00892, 0.01])\n",
    "test_mus = np.asarray([0.00397, 0.00793])\n",
    "train_sols, test_sols = split_data_by_mu(mus, sols, train_mus, test_mus) # mus X variables X time X space_x X space_y\n",
    "n_mu_train, n_q, n_t, n_x1, n_x2 = train_sols.shape\n",
    "n_mu_test, n_q, n_t, n_x1, n_x2 = test_sols.shape\n",
    "time = spacing[1]\n",
    "x_space = spacing[2]\n",
    "y_space = spacing[3]\n",
    "\n",
    "print(f'n_mu train: {n_mu_train}, n_mu test: {n_mu_test}, n_variables: {n_q}, n_time samples: {n_t}, n_x samples: {n_x1}, n_x2 samples: {n_x2}')\n",
    "print(time)\n",
    "print(x_space)\n",
    "print(y_space)\n",
    "\n",
    "y_train, mu_t_train, X_grid =  prepare_coordinate_data(spacing, train_mus, train_sols)\n",
    "y_test, mu_t_test, X_grid =  prepare_coordinate_data(spacing, test_mus, test_sols)\n",
    "\n",
    "def normalize(x, mean, std):\n",
    "    return (x-mean)/std\n",
    "\n",
    "mean, std = jnp.mean(mu_t_train, axis=0), jnp.std(mu_t_train, axis=0)\n",
    "mu_t_train = normalize(mu_t_train, mean, std)\n",
    "mu_t_test = normalize(mu_t_test, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colora.build import build_colora\n",
    "\n",
    "key = jax.random.PRNGKey(1)\n",
    "\n",
    "x_dim = 2\n",
    "mu_t_dim = 2\n",
    "u_dim = 1\n",
    "\n",
    "d_len_x = x_space[-1] - x_space[0]\n",
    "d_len_y = y_space[-1] - y_space[0]\n",
    "\n",
    "\n",
    "u_layers = ['P', 'C', 'C', 'C', 'C', 'C', 'C', 'C'] # seven colora layers with 1 alpha each means we will have laten dim of 7\n",
    "g_layers = ['D', 'D', 'D', 'END'] # now g takes in phi(t,mu) and psi and outputs the time derivative of phi\n",
    "rank = 3\n",
    "\n",
    "u_hat_config = {'width': 25, 'layers': u_layers}\n",
    "g_config = {'width': 15, 'layers': g_layers}\n",
    "\n",
    "u_hat_fn, g_fn, theta_init, psi_init = build_colora(\n",
    "    u_hat_config, g_config, x_dim, mu_t_dim, u_dim, lora_filter=['alpha'],period=[d_len_x, d_len_y], rank=rank, key=key)\n",
    "\n",
    "#check neural ODE is correctly defined\n",
    "\n",
    "print(g_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_hat_v_x =  vmap(u_hat_fn, in_axes=(None, None, 0)) # vmaped over x to generate solution field over space points\n",
    "u_hat_v_x_phi =  vmap(u_hat_v_x, in_axes=(None, 0, None)) # vmaped over x to generate solution field over space points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_phi = len(u_layers)-1\n",
    "phi_init = jnp.zeros(n_phi)\n",
    "\n",
    "# define time integrator for g(phi(t, mu), psi) and vmap over mu\n",
    "def integrate_g_forall_mu(g_fn, phi_init, time, mu_t, X_grid):\n",
    "    batched_integrator = vmap(odeint, in_axes=(None, None, None, 0, None))\n",
    "    phi_forall_mu = batched_integrator(g_fn, phi_init, time, mu_t, X_grid)\n",
    "    return phi_forall_mu\n",
    "\n",
    "# we will now define loss interms of the params of u_hat and g\n",
    "def predict(psi_theta,mu_t, X_grid):\n",
    "    psi, theta = psi_theta\n",
    "    phi = integrate_g_forall_mu(g_fn_vmap, phi_init, time, mu_t, X_grid)\n",
    "    u_hat = u_hat_v_x_phi(theta, phi, X_grid)\n",
    "    return u_hat\n",
    "\n",
    "def loss_NODE(psi_theta,sols, mu_t, X_grid):\n",
    "    pred=predict(psi_theta,mu_t, X_grid)\n",
    "    loss = jnp.linalg.norm(\n",
    "        sols - pred, axis=(1,2)) / jnp.linalg.norm(sols, axis=(1,2))\n",
    "    return jnp.mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Given by GPT\n",
    "n_phi = len(u_layers) - 1\n",
    "phi_init = jnp.ones(n_phi)\n",
    "\n",
    "# def integrate_g_vmap_mu(g_fn, phi_init, time, mu_t): # integrate g over all time for all mu\n",
    "#     batched_integrator = vmap(odeint, in_axes=(None, None, None, 0))\n",
    "#     phi_forall_mu = batched_integrator(g_fn, phi_init, time, mu_t)\n",
    "#     return phi_forall_mu\n",
    "\n",
    "# def predict(psi_theta, phi_init, time, mu_t, X_grid):\n",
    "#     psi, theta = psi_theta\n",
    "#     phi = integrate_g_vmap_mu(g_fn, phi_init, time, mu_t)\n",
    "#     pred = u_hat_v_x_phi(theta, phi, X_grid)\n",
    "#     return pred\n",
    "\n",
    "def predict(g_fn, psi_theta, phi_init, time, mu_t, X_grid):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - g_fn: The function representing the neural ODE's RHS, which outputs time derivatives of phi.\n",
    "    - psi_theta: Tuple containing the parameters for psi and theta.\n",
    "    - phi_init: Initial conditions for phi.\n",
    "    - time: Array of time points for integration.\n",
    "    - mu_t: Array of mu values, one for each scenario to integrate over.\n",
    "    - X_grid: Spatial grid points at which evaluations are required.\n",
    "    Returns:\n",
    "    - Predicted values of u_hat across all time points, mu values, and spatial points.\n",
    "    \"\"\"\n",
    "    psi, theta = psi_theta\n",
    "    \n",
    "    # Integrate over all mu values using vmap for batch processing\n",
    "    batched_integrator = vmap(odeint, in_axes=(None, None, None, 0))\n",
    "    phi_forall_mu = batched_integrator(g_fn, phi_init, time, mu_t)\n",
    "\n",
    "    # Evaluate u_hat_fn using the results of the integration, vectorized over all mu and spatial points\n",
    "    # Assuming u_hat_fn is structured to take inputs (theta, phi, X_grid)\n",
    "    # and that it can handle batched inputs for phi and X_grid\n",
    "    u_hat_v_x_phi = vmap(vmap(u_hat_fn, in_axes=(None, None,0)), in_axes=(None, 0, None))\n",
    "    pred = u_hat_v_x_phi(theta, phi_forall_mu, X_grid)\n",
    "    return pred\n",
    "\n",
    "\n",
    "def loss_NODE(psi_theta, mu_t, sols, X_grid):\n",
    "    pred = predict(psi_theta, time, mu_t, X_grid)\n",
    "    print(\"Shapes - sols: {}, pred: {}\".format(sols.shape, pred.shape))\n",
    "    loss = jnp.linalg.norm(\n",
    "        sols - pred, axis=(1, 2)) / jnp.linalg.norm(sols, axis=(1, 2))\n",
    "    return jnp.mean(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colora.data import Dataset\n",
    "\n",
    "# the dataset is just responsible for batching the data over the mu_t tensor \n",
    "# in order to aviod memory overflow on the GPU\n",
    "dataset = Dataset(mu_t_train, X_grid, y_train, n_batches=15, key=key)\n",
    "dataset = iter(dataset)\n",
    "def args_fn():\n",
    "    return next(dataset),\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "loss_NODE() missing 3 required positional arguments: 'sols', 'mu_t', and 'X_grid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[124], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcolora\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adam_opt\n\u001b[1;32m      3\u001b[0m psi_theta \u001b[38;5;241m=\u001b[39m (psi_init, theta_init)\n\u001b[0;32m----> 4\u001b[0m opt_psi_theta, loss_history \u001b[38;5;241m=\u001b[39m \u001b[43madam_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsi_theta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_NODE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \n\u001b[1;32m      5\u001b[0m opt_psi, opt_theta \u001b[38;5;241m=\u001b[39m opt_psi_theta\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(opt_psi_theta)\n",
      "File \u001b[0;32m~/Desktop/codes/PDE/CoLoRA-main/colora/adam.py:56\u001b[0m, in \u001b[0;36madam_opt\u001b[0;34m(theta_init, loss_fn, args_fn, init_state, steps, learning_rate, scheduler, verbose, loss_tol, optimizer)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     args \u001b[38;5;241m=\u001b[39m args_fn\n\u001b[0;32m---> 56\u001b[0m cur_loss, params_new, state_new \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcur_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3E\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m n_rec:\n",
      "    \u001b[0;31m[... skipping hidden 12 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/codes/PDE/CoLoRA-main/colora/adam.py:37\u001b[0m, in \u001b[0;36madam_opt.<locals>.step\u001b[0;34m(params, state, args)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;129m@jit\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(params, state, args):\n\u001b[0;32m---> 37\u001b[0m     loss_value, grads \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_and_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     updates, state \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mupdate(grads, state, params)\n\u001b[1;32m     40\u001b[0m     params \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mapply_updates(params, updates)\n",
      "    \u001b[0;31m[... skipping hidden 7 frame]\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/jax/_src/linear_util.py:191\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m gen \u001b[38;5;241m=\u001b[39m gen_static_args \u001b[38;5;241m=\u001b[39m out_store \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 191\u001b[0m   ans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    193\u001b[0m   \u001b[38;5;66;03m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    194\u001b[0m   \u001b[38;5;66;03m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;66;03m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    196\u001b[0m   \u001b[38;5;66;03m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    197\u001b[0m   \u001b[38;5;66;03m# state.\u001b[39;00m\n\u001b[1;32m    198\u001b[0m   \u001b[38;5;28;01mwhile\u001b[39;00m stack:\n",
      "\u001b[0;31mTypeError\u001b[0m: loss_NODE() missing 3 required positional arguments: 'sols', 'mu_t', and 'X_grid'"
     ]
    }
   ],
   "source": [
    "from colora.adam import adam_opt\n",
    "\n",
    "psi_theta = (psi_init, theta_init)\n",
    "opt_psi_theta, loss_history = adam_opt(psi_theta, loss_NODE, args_fn, steps=100, learning_rate=5e-3, verbose=True) \n",
    "opt_psi, opt_theta = opt_psi_theta\n",
    "\n",
    "print(opt_psi_theta)\n",
    "print(opt_psi)\n",
    "print(opt_theta)\n",
    "\n",
    "pred = predict(opt_psi_theta, mu_t_test, X_grid)\n",
    "pred = rearrange(pred, '(M T) (N1 N2) Q -> M Q T N1 N2', Q=n_q, T=n_t, N1=n_x1, N2=n_x2)\n",
    "\n",
    "test_vec =  rearrange(test_sols, 'M Q T N1 N2 -> M (Q T N1 N2)')\n",
    "pred_vec =  rearrange(pred, 'M Q T N1 N2 -> M (Q T N1 N2)')\n",
    "rel_err = np.linalg.norm(test_vec - pred_vec, axis=1) / np.linalg.norm(test_vec, axis=1)\n",
    "mean_rel_err = rel_err.mean()\n",
    "print(f'Test mean relative error: {mean_rel_err:.2E}')\n",
    "from colora.plot import imshow_movie\n",
    "\n",
    "imshow_movie(pred[0][0], save_to='./img/burgers.gif', t=spacing[1], title='Burgers', tight=True, live_cbar=True, frames=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(opt_psi_theta)\n",
    "print(opt_psi)\n",
    "print(opt_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = predict(opt_psi_theta, mu_t_test, X_grid)\n",
    "pred = rearrange(pred, '(M T) (N1 N2) Q -> M Q T N1 N2', Q=n_q, T=n_t, N1=n_x1, N2=n_x2)\n",
    "\n",
    "test_vec =  rearrange(test_sols, 'M Q T N1 N2 -> M (Q T N1 N2)')\n",
    "pred_vec =  rearrange(pred, 'M Q T N1 N2 -> M (Q T N1 N2)')\n",
    "rel_err = np.linalg.norm(test_vec- pred_vec, axis=1)/np.linalg.norm(test_vec, axis=1)\n",
    "mean_rel_err = rel_err.mean()\n",
    "print(f'Test mean relative error: {mean_rel_err:.2E}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colora.plot import imshow_movie\n",
    "\n",
    "imshow_movie(pred[0][0], save_to='./img/burgers.gif', t=spacing[1], title='Burgers', tight=True, live_cbar=True, frames=85)\n",
    "\n",
    "phis = h_v_mu_t(opt_psi, mu_t_test)\n",
    "phis = rearrange(phis, '(M T) D -> M T D', T=n_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colora.plot import trajectory_movie\n",
    "leg= []\n",
    "for i in range(phis.shape[-1]):\n",
    "    lstr =rf'$\\phi_{i}$'\n",
    "    leg.append(lstr)\n",
    "trajectory_movie(phis[0], x=time, title='Burgers', ylabel=r'$\\phi(t;\\mu)$', legend=leg, save_to='./img/burgers_dynamics', frames=85)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
