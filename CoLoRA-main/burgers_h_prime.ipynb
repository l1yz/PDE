{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cuda(id=0)]\n"
     ]
    }
   ],
   "source": [
    "from jax import vmap\n",
    "import jax.numpy as jnp\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "import jax\n",
    "import matplotlib.pyplot as plt\n",
    "print(jax.devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_mu train: 8, n_mu test: 2, n_variables: 1, n_time samples: 51, n_x samples: 129, n_x2 samples: 129\n"
     ]
    }
   ],
   "source": [
    "from colora.data import load_all_hdf5, split_data_by_mu, prepare_coordinate_data\n",
    "data_dir = Path('./data')\n",
    "data_path = data_dir / 'burgers'\n",
    "mus, sols, spacing = load_all_hdf5(data_path)\n",
    "\n",
    "train_mus = np.asarray([0.001, 0.00199, 0.00298, 0.00496, 0.00595, 0.00694, 0.00892, 0.01])\n",
    "test_mus = np.asarray([0.00397, 0.00793])\n",
    "train_sols, test_sols = split_data_by_mu(mus, sols, train_mus, test_mus) # mus X variables X time X space_x X space_y\n",
    "n_mu_train, n_q, n_t, n_x1, n_x2 = train_sols.shape\n",
    "n_mu_test, n_q, n_t, n_x1, n_x2 = test_sols.shape\n",
    "time = spacing[1]\n",
    "x_space = spacing[2]\n",
    "y_space = spacing[3]\n",
    "\n",
    "print(f'n_mu train: {n_mu_train}, n_mu test: {n_mu_test}, n_variables: {n_q}, n_time samples: {n_t}, n_x samples: {n_x1}, n_x2 samples: {n_x2}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, mu_t_train, X_grid =  prepare_coordinate_data(spacing, train_mus, train_sols)\n",
    "y_test, mu_t_test, X_grid =  prepare_coordinate_data(spacing, test_mus, test_sols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, mean, std):\n",
    "    return (x-mean)/std\n",
    "\n",
    "mean, std = jnp.mean(mu_t_train, axis=0), jnp.std(mu_t_train, axis=0)\n",
    "mu_t_train = normalize(mu_t_train, mean, std)\n",
    "mu_t_test = normalize(mu_t_test, mean, std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colora.build import build_colora\n",
    "\n",
    "key = jax.random.PRNGKey(1)\n",
    "\n",
    "x_dim = 2\n",
    "mu_t_dim = 2\n",
    "u_dim = 1\n",
    "\n",
    "d_len_x = x_space[-1] - x_space[0]\n",
    "d_len_y = y_space[-1] - y_space[0]\n",
    "\n",
    "\"\"\"modify for experiments\n",
    "\"\"\"\n",
    "u_layers = ['P', 'C', 'C', 'C', 'C', 'C', 'C', 'C'] # seven colora layers with 1 alpha each means we will have latent dim of 7\n",
    "h_layers = ['D', 'D', 'D']\n",
    "rank = 3\n",
    "# made the nn smaller for taining purposes\n",
    "u_hat_config = {'width': 25, 'layers': u_layers}\n",
    "h_config = {'width': 15, 'layers': h_layers}\n",
    "\n",
    "u_hat_fn, h_fn, theta_init, psi_init = build_colora(\n",
    "    u_hat_config, h_config, x_dim, mu_t_dim, u_dim, lora_filter=['alpha'],period=[d_len_x, d_len_y], rank=rank, key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h_v_mu_t = vmap(h_fn, in_axes=(None, 0)) # vmap over mu_t array to generate array of phis\n",
    "u_hat_v_x =  vmap(u_hat_fn, in_axes=(None, None, 0)) # vmaped over x to generate solution field over space points\n",
    "u_hat_v_x_phi =  vmap(u_hat_v_x, in_axes=(None, 0, None)) # vmaped over x to generate solution field over space points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(psi_theta, mu_t, X_grid):\n",
    "    psi, theta = psi_theta\n",
    "    phis = h_v_mu_t(psi, mu_t)\n",
    "    pred = u_hat_v_x_phi(theta, phis, X_grid)\n",
    "    return pred\n",
    "\n",
    "def relative_loss_fn(psi_theta, mu_t, sols, X_grid):\n",
    "    pred = predict(psi_theta, mu_t, X_grid)\n",
    "    loss = jnp.linalg.norm(\n",
    "        sols - pred, axis=(1,2)) / jnp.linalg.norm(sols, axis=(1,2))\n",
    "    return loss.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2edec9159cc4b09b065472c64eba3f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcolora\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madam\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adam_opt\n\u001b[1;32m     12\u001b[0m psi_theta \u001b[38;5;241m=\u001b[39m (psi_init, theta_init)\n\u001b[0;32m---> 13\u001b[0m opt_psi_theta, loss_history \u001b[38;5;241m=\u001b[39m \u001b[43madam_opt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsi_theta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrelative_loss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50_000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m opt_psi, opt_theta \u001b[38;5;241m=\u001b[39m opt_psi_theta\n",
      "File \u001b[0;32m/scratch/yl8517/CoLoRA-main/colora/adam.py:58\u001b[0m, in \u001b[0;36madam_opt\u001b[0;34m(theta_init, loss_fn, args_fn, init_state, steps, learning_rate, scheduler, verbose, loss_tol, optimizer)\u001b[0m\n\u001b[1;32m     54\u001b[0m     args \u001b[38;5;241m=\u001b[39m args_fn\n\u001b[1;32m     56\u001b[0m cur_loss, params_new, state_new \u001b[38;5;241m=\u001b[39m step(params, state, args)\n\u001b[0;32m---> 58\u001b[0m pbar\u001b[38;5;241m.\u001b[39mset_postfix({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcur_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3E\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m n_rec:\n\u001b[1;32m     61\u001b[0m     loss_history\u001b[38;5;241m.\u001b[39mappend(cur_loss)\n",
      "File \u001b[0;32m/scratch/yl8517/myvenv/lib/python3.11/site-packages/jax/_src/array.py:295\u001b[0m, in \u001b[0;36mArrayImpl.__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__format__\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_spec):\n\u001b[1;32m    293\u001b[0m   \u001b[38;5;66;03m# Simulates behavior of https://github.com/numpy/numpy/pull/9883\u001b[39;00m\n\u001b[1;32m    294\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 295\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_value\u001b[49m[()], format_spec)\n\u001b[1;32m    296\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value, format_spec)\n",
      "File \u001b[0;32m/scratch/yl8517/myvenv/lib/python3.11/site-packages/jax/_src/profiler.py:335\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    334\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m TraceAnnotation(name, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m/scratch/yl8517/myvenv/lib/python3.11/site-packages/jax/_src/array.py:594\u001b[0m, in \u001b[0;36mArrayImpl._value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    593\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_fully_replicated:\n\u001b[0;32m--> 594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_single_device_array_to_np_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_npy_value)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from colora.data import Dataset\n",
    "\n",
    "# the dataset is just responsible for batching the data over the mu_t tensor \n",
    "# in order to aviod memory overflow on the GPU\n",
    "dataset = Dataset(mu_t_train, X_grid, y_train, n_batches=25, key=key)\n",
    "dataset = iter(dataset)\n",
    "def args_fn():\n",
    "    return next(dataset)\n",
    "\n",
    "from colora.adam import adam_opt\n",
    "\n",
    "psi_theta = (psi_init, theta_init)\n",
    "opt_psi_theta, loss_history = adam_opt(psi_theta, relative_loss_fn, args_fn, steps=50_000, learning_rate=5e-3, verbose=True)\n",
    "opt_psi, opt_theta = opt_psi_theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # we first use pickle to save the psi and theta\n",
    "\n",
    "# # trained 50k steps\n",
    "\n",
    "# import pickle\n",
    "# with open('opt_psi.pkl', 'wb') as f:\n",
    "#     pickle.dump(opt_psi, f)\n",
    "# with open('opt_theta.pkl', 'wb') as f:\n",
    "#     pickle.dump(opt_theta, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load optimal psi and theta\n",
    "# import pickle\n",
    "# with open('opt_psi.pkl', 'rb') as f:\n",
    "#     opt_psi = pickle.load(f)\n",
    "# with open('opt_theta.pkl', 'rb') as f:\n",
    "#     opt_theta = pickle.load(f)\n",
    "\n",
    "# opt_psi_theta=(opt_psi,opt_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test relative loss\n",
    "pred = predict(opt_psi_theta, mu_t_test, X_grid)\n",
    "pred = rearrange(pred, '(M T) (N1 N2) Q -> M Q T N1 N2', Q=n_q, T=n_t, N1=n_x1, N2=n_x2)\n",
    "test_vec =  rearrange(test_sols, 'M Q T N1 N2 -> M (Q T N1 N2)')\n",
    "pred_vec =  rearrange(pred, 'M Q T N1 N2 -> M (Q T N1 N2)')\n",
    "rel_err = np.linalg.norm(test_vec- pred_vec, axis=1)/np.linalg.norm(test_vec, axis=1)\n",
    "mean_rel_err = rel_err.mean()\n",
    "print(f'Test mean relative error: {mean_rel_err:.2E}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colora.plot import imshow_movie\n",
    "\n",
    "imshow_movie(pred[0][0], save_to='./img/burgers_test/burgers.gif', t=jnp.linspace(0,5,251), title='Burgers', tight=True, live_cbar=True, frames=85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phis = h_v_mu_t(opt_psi, mu_t_test)\n",
    "\n",
    "phis = rearrange(phis, '(M T) D -> M T D', T=n_t)\n",
    "\n",
    "from colora.plot import trajectory_movie\n",
    "leg= []\n",
    "for i in range(phis.shape[-1]):\n",
    "    lstr =rf'$\\phi_{i}$'\n",
    "    leg.append(lstr)\n",
    "#plot latent trajectories for the 1st test mu.\n",
    "trajectory_movie(phis[0], x=time, title='Burgers', ylabel=r'$\\phi(t;\\mu)$', legend=leg, save_to='./img/burgers_test/burgers_dynamics', frames=85) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**make prediction of the dynamics beyond the trained time frame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' somehow wrong: the movie starts at t=1\n",
    "'''\n",
    "\n",
    "# Extend the time span for prediction\n",
    "extended_time = jnp.linspace(0, 4 * time[-1], 4 * len(time)-3)  # Example: 4 times time span\n",
    "\n",
    "extended_mu_t_test = []\n",
    "for mu in test_mus:\n",
    "    for t in extended_time:\n",
    "        extended_mu_t_test.append([mu, t])\n",
    "extended_mu_t_test = jnp.array(extended_mu_t_test)\n",
    "\n",
    "\n",
    "# Predict extended time\n",
    "\n",
    "def predict_extended(psi_theta, mu_t, X_grid):\n",
    "    psi, theta = psi_theta\n",
    "    phis = h_v_mu_t(psi, mu_t)\n",
    "    pred = u_hat_v_x_phi(theta, phis, X_grid)\n",
    "    return pred\n",
    "\n",
    "pred_extended = predict_extended(opt_psi_theta, extended_mu_t_test, X_grid)\n",
    "n_t_extended = len(extended_time)\n",
    "pred_extended = rearrange(pred_extended, '(M T) (N1 N2) Q -> M Q T N1 N2', Q=n_q, T=n_t_extended, N1=n_x1, N2=n_x2)\n",
    "\n",
    "imshow_movie(pred_extended[0][0], frames=201, t=extended_time, save_to='./img/burgers_test/burgers_extended.gif', title='Burgers Extended', tight=True, live_cbar=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now relearn the dynamics with NODE with IC** $\\phi_0(\\mu)=h(0,\\mu,opt\\_psi)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the initial condition phi(0, mu) from the trained hypernetwork\n",
    "def get_all_phi_0(psi, mu):\n",
    "    mu_0 = jnp.column_stack((mu, jnp.zeros(mu.shape[0])))\n",
    "    # normalize mu_0\n",
    "    mu_0 = normalize(mu_0, mean, std)\n",
    "    return h_v_mu_t(psi, mu_0)\n",
    "\n",
    "\n",
    "# calculate phi0 for train mus\n",
    "phi_0_mus_train = get_all_phi_0(opt_psi, train_mus)\n",
    "\n",
    "print(phi_0_mus_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Proposed approach: \\partial_t phi(t,mu ) = g(phi(t,mu), mu ;omega)\n",
    "CHANGE ACTIVATION OF MLP ?\n",
    "'''\n",
    "from colora.NODE import NODE\n",
    "keygen = 123\n",
    "phi_dim = 7  #change this if needed \n",
    "mu_dim = 1   \n",
    "hidden_dim = 20\n",
    "depth = 4\n",
    "\n",
    "# build g\n",
    "g = NODE(phi_dim, mu_dim, hidden_dim, depth, keygen) # g takes in phi and mu and outputs the time derivative of phi\n",
    "\n",
    "#record tree shape\n",
    "omega,omega_def = jax.tree_util.tree_flatten(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not flattened pred and loss (see equinox faq)\n",
    "\n",
    "#@eqx.filter_grad\n",
    "# import functools as ft\n",
    "# @ft.partial(jax.jit,static_argnums=1)\n",
    "import equinox as eqx\n",
    "def predictNODE(omega_theta, omega_def, t_span, mus, X_grid, phi_0):\n",
    "    omega, theta = omega_theta\n",
    "    g=jax.tree_util.tree_unflatten(omega_def, omega)\n",
    "    g_forall_phi_mu = vmap(g, in_axes=(0, 0, None)) # pack (phi0_i,mu_i)\n",
    "\n",
    "    # get phis\n",
    "    phis=g_forall_phi_mu(phi_0, mus, t_span)\n",
    "    # reshape phis to match the shape of sols later\n",
    "    phis=phis.reshape(-1,phi_dim)\n",
    "\n",
    "    pred = u_hat_v_x_phi(theta, phis, X_grid)\n",
    "    return pred\n",
    "\n",
    "def lossNODE(omega_theta, omega_def, t_span, mus, sols, X_grid, phi_0):\n",
    "    #omega_flat, theta = omega_flat_theta\n",
    "    pred = predictNODE(omega_theta, omega_def, t_span, mus, X_grid,phi_0)\n",
    "\n",
    "    loss = jnp.linalg.norm(\n",
    "        sols - pred, axis=(1,2)) / jnp.linalg.norm(sols, axis=(1,2))\n",
    "    return loss.mean()\n",
    "\n",
    "t_span = jnp.linspace(0.0, 1.0, 51)\n",
    "\n",
    "omega_theta = (omega, opt_theta)\n",
    "\n",
    "#g_forall_phi_mu(phi_0_mus_train, train_mus, t_span)\n",
    "loss=lossNODE(omega_theta, omega_def, t_span, train_mus, y_train, X_grid, phi_0_mus_train)\n",
    "print(loss)\n",
    "eqxgrad_lossNODE = eqx.filter_value_and_grad(lossNODE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# not flattened training\n",
    "\n",
    "ys = y_train\n",
    "mus = train_mus\n",
    "\n",
    "import optax\n",
    "optimizer=optax.adam(1e-3)\n",
    "opt_state=optimizer.init(eqx.filter(omega_theta, eqx.is_inexact_array))\n",
    "\n",
    "@eqx.filter_jit\n",
    "def update(omega_theta, omega_def, t_span, mus, sols, X_grid, phi_0, opt_state):\n",
    "    loss,grad = eqxgrad_lossNODE(omega_theta, omega_def, t_span, mus, sols, X_grid, phi_0)\n",
    "\n",
    "    updates, new_opt_state=optimizer.update(grad,opt_state)\n",
    "    \n",
    "    new_omega_theta=eqx.apply_updates(omega_theta,updates)\n",
    "\n",
    "    return new_omega_theta, new_opt_state, loss\n",
    "\n",
    "n_steps=5000\n",
    "losses=[]\n",
    "import time as timer\n",
    "\n",
    "for i in range(n_steps):\n",
    "    start=timer.time()\n",
    "    omega_theta, opt_state, loss = update(omega_theta, omega_def, t_span, mus, ys, X_grid, phi_0_mus_train, opt_state)\n",
    "    losses.append(loss)\n",
    "    \n",
    "    if i % 100 ==0:\n",
    "        end=timer.time()\n",
    "        print(f\"{i}th iter, loss={loss}, time={end-start}\")\n",
    "plt.plot(losses)\n",
    "plt.xlabel('iteration')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('loss')\n",
    "plt.title('NODE loss')\n",
    "plt.savefig('NODE_loss.png')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have the updated omega_flat_theta, we first test its performance on the test set\n",
    "ys = y_test\n",
    "mus = test_mus\n",
    "# note omega_flat_theta is trained\n",
    "phi_0_mus_test = get_all_phi_0(opt_psi, test_mus)\n",
    "loss_on_test=lossNODE(\n",
    "    omega_theta, omega_def, t_span, mus, ys, X_grid, phi_0_mus_test)\n",
    "\n",
    "print(loss_on_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check the same relative loss\n",
    "pred = predictNODE(omega_theta, omega_def, t_span, test_mus, X_grid, phi_0_mus_test)#removed an argument for nonflattend \n",
    "pred = rearrange(pred, '(M T) (N1 N2) Q -> M Q T N1 N2', Q=n_q, T=n_t, N1=n_x1, N2=n_x2)\n",
    "\n",
    "test_vec =  rearrange(test_sols, 'M Q T N1 N2 -> M (Q T N1 N2)')\n",
    "pred_vec =  rearrange(pred, 'M Q T N1 N2 -> M (Q T N1 N2)')\n",
    "rel_err = np.linalg.norm(test_vec- pred_vec, axis=1)/np.linalg.norm(test_vec, axis=1)\n",
    "mean_rel_err = rel_err.mean()\n",
    "print(f'Test mean relative error: {mean_rel_err:.2E}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we can plot the prediction given by the trained model\n",
    "from colora.plot import imshow_movie\n",
    "\n",
    "imshow_movie(pred[0][0], save_to='./img/burgers_test/burgers_NODE.gif', t=jnp.linspace(0,1,51), title='Burgers NODE', tight=True, live_cbar=True, frames=171)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the dynamics of phi_i's by integrating g with the trained omega\n",
    "opt_omega,reopt_theta = omega_theta\n",
    "\n",
    "phi_0_mus_test = get_all_phi_0(opt_psi, test_mus)\n",
    "\n",
    "g=jax.tree_util.tree_unflatten(omega_def,opt_omega)\n",
    "g_forall_phi_mu = vmap(g, in_axes=(0, 0, None))\n",
    "\n",
    "phis = g(phi_0_mus_test[0], test_mus[0], t_span)\n",
    "print(phis.shape)\n",
    "\n",
    "\n",
    "from colora.plot import trajectory_movie\n",
    "leg= []\n",
    "for i in range(phis.shape[-1]):\n",
    "    lstr =rf'$\\phi_{i}$'\n",
    "    leg.append(lstr)\n",
    "trajectory_movie(phis, x=t_span, title='Burgers NODE', ylabel=r'$\\phi(t;\\mu)$', legend=leg, save_to='./img/burgers_test/burgers_NODE_dynamics', frames=85)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction beyond window with NODE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we predict it for longer time frame by integrating g over a longer time span\n",
    "extended_time = jnp.linspace(0, 5 * time[-1], 5 * len(time))  # Example: double the time span\n",
    "t_span = extended_time\n",
    "phi_0_mus_test = get_all_phi_0(opt_psi, test_mus)\n",
    "pred_extended = predictNODE(omega_theta, omega_def, t_span, test_mus, X_grid, phi_0_mus_test)\n",
    "n_t_extended = len(extended_time)\n",
    "pred_extended = rearrange(pred_extended, '(M T) (N1 N2) Q -> M Q T N1 N2', Q=n_q, T=n_t_extended, N1=n_x1, N2=n_x2)\n",
    "\n",
    "\n",
    "imshow_movie(pred_extended[0][0], frames=100, t=extended_time, save_to='./img/burgers_test/burgers_NODE_extended.gif', title='Burgers NODE Extended', tight=True, live_cbar=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the dynamics of phi_i's by integrating g with the trained omega\n",
    "opt_omega,reopt_theta = omega_theta\n",
    "phi_0_mus_test = get_all_phi_0(opt_psi, test_mus)\n",
    "\n",
    "g=jax.tree_util.tree_unflatten(omega_def,opt_omega)\n",
    "g_forall_phi_mu = vmap(g, in_axes=(0, 0, None))\n",
    "\n",
    "phis_extended = g(phi_0_mus_test[0], test_mus[0], extended_time)\n",
    "print(phis.shape)\n",
    "\n",
    "\n",
    "from colora.plot import trajectory_movie\n",
    "leg= []\n",
    "for i in range(phis.shape[-1]):\n",
    "    lstr =rf'$\\phi_{i}$'\n",
    "    leg.append(lstr)\n",
    "trajectory_movie(phis_extended, x=extended_time, title='Burgers NODE', ylabel=r'$\\phi(t;\\mu)$', legend=leg, save_to='./img/burgers_test/burgers_NODE_dynamics_extended', frames=85)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learn latent grid directly (not done)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This learns the time derivative of phi by constructi h_prime(mu,t,omega)=dphi/dt\n",
    "'''\n",
    "import equinox as eqx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.flatten_util import ravel_pytree\n",
    "import diffrax\n",
    "import optax\n",
    "#import numpy as np\n",
    "\n",
    "class ODEFunc_NODE(eqx.Module):\n",
    "    mlp: eqx.nn.MLP\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, depth, key):\n",
    "        super().__init__()\n",
    "        self.mlp = eqx.nn.MLP(input_dim, output_dim, hidden_dim, depth, key=key)\n",
    "\n",
    "    def __call__(self, t, y, mu):\n",
    "        # Combine time, state, and mu into a single input vector\n",
    "        input = jnp.concatenate([jnp.array([t]), y, mu])\n",
    "        return self.mlp(input)\n",
    "\n",
    "class NeuralODE_h_prime(eqx.Module):\n",
    "    ode_func: ODEFunc_NODE\n",
    "\n",
    "    def __init__(self, mu_t_dim, hidden_dim, phi_dim, depth, key):\n",
    "        super().__init__()\n",
    "        self.ode_func = ODEFunc(mu_t_dim, hidden_dim, phi_dim, depth, key)\n",
    "\n",
    "    def __call__(self, y0, mu, t_span):\n",
    "        def func(t, y, args):\n",
    "            return self.ode_func(t, y, mu)\n",
    "\n",
    "        solver = diffrax.Tsit5()\n",
    "        saveat = diffrax.SaveAt(ts=t_span)\n",
    "        sol = diffrax.diffeqsolve(\n",
    "            diffrax.ODETerm(func),\n",
    "            solver,\n",
    "            t0=t_span[0],\n",
    "            t1=t_span[-1],\n",
    "            dt0=t_span[1] - t_span[0],\n",
    "            y0=y0,\n",
    "            saveat=saveat\n",
    "        )\n",
    "        return sol.ys\n",
    "\n",
    "n_phi = 7\n",
    "mu_t_dim=2 # 1 mu and 1 t\n",
    "hidden_dim=10\n",
    "output_dim=n_phi\n",
    "depth=3\n",
    "\n",
    "hp=NeuralODE_h_prime(mu_t_dim, hidden_dim, output_dim, depth, key)\n",
    "\n",
    "params_hp, hp_def = jax.tree_util.tree_flatten(hp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate training materials\n",
    "phis_train=h_v_mu_t(opt_psi, mu_t_train)\n",
    "phis_test=h_v_mu_t(opt_psi, mu_t_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_hp(params_hp, hp_def, t_span,mus, phi_0):\n",
    "    hp=jax.tree_util.tree_unflatten(hp_def, params_hp)\n",
    "    \n",
    "    hp_forall_phi_mu = vmap(hp, in_axes=(0, 0, None)) # pack (phi0_i,mu_i)\n",
    "\n",
    "    phis=hp_forall_phi_mu(phi_0, mus, t_span)\n",
    "    # reshape phis to match the shape of sols later\n",
    "    phis=phis.reshape(-1,n_phi)\n",
    "\n",
    "    return phis\n",
    "def loss_hp(params_hp,hp_def, t_span, mus, phi_target, phi_0):\n",
    "    \n",
    "    pred = predict_hp(params_hp, hp_def, t_span, mus, phi_0)\n",
    "    loss = jnp.linalg.norm(\n",
    "        phi_target - pred, axis=(1,2)) / jnp.linalg.norm(phis, axis=(1,2))\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "t_span = jnp.linspace(0.0, 1.0, 51)\n",
    "\n",
    "phi_target=phis_train\n",
    "\n",
    "mus = train_mus\n",
    "\n",
    "loss=loss_hp(params_hp, hp_def, t_span, mus, phi_target, phi_0_mus_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
